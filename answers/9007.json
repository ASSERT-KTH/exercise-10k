{
  "prompt": "Create a function that uses caching to store the results of expensive function calls.",
  "answer": "**Function Caching using Memoization**\n=====================================\n\nHere's an example of a function that uses caching to store the results of expensive function calls. We'll use Python's built-in `functools` module, which provides a decorator called `lru_cache` that can be used to cache function results.\n\n```python\nimport functools\nimport time\n\ndef expensive_function(x):\n    \"\"\"Simulate an expensive function call\"\"\"\n    time.sleep(2)  # Simulate a 2-second delay\n    return x * x\n\n@functools.lru_cache(maxsize=None)\ndef cached_expensive_function(x):\n    \"\"\"Cache the results of expensive function calls\"\"\"\n    return expensive_function(x)\n\n# Example usage\nif __name__ == \"__main__\":\n    print(\"Calling cached_expensive_function(5)...\")\n    start_time = time.time()\n    result1 = cached_expensive_function(5)\n    end_time = time.time()\n    print(f\"Result: {result1}, Time taken: {end_time - start_time} seconds\")\n\n    print(\"\\nCalling cached_expensive_function(5) again...\")\n    start_time = time.time()\n    result2 = cached_expensive_function(5)\n    end_time = time.time()\n    print(f\"Result: {result2}, Time taken: {end_time - start_time} seconds\")\n\n    print(\"\\nCalling cached_expensive_function(10)...\")\n    start_time = time.time()\n    result3 = cached_expensive_function(10)\n    end_time = time.time()\n    print(f\"Result: {result3}, Time taken: {end_time - start_time} seconds\")\n```\n\n**How it works**\n\n1. The `expensive_function` simulates an expensive function call by sleeping for 2 seconds and then returning the square of the input.\n2. The `cached_expensive_function` uses the `@functools.lru_cache` decorator to cache its results. The `maxsize` parameter is set to `None`, which means the cache will store results for all input values.\n3. When `cached_expensive_function` is called, it checks the cache first. If the result is already cached, it returns the cached result immediately.\n4. If the result is not cached, it calls the `expensive_function` and stores the result in the cache before returning it.\n\n**Benefits**\n\n* Reduces the time taken for repeated function calls with the same input values.\n* Improves performance by avoiding redundant computations.\n\nNote: The `lru_cache` decorator uses a least-recently-used (LRU) eviction policy, which means that the least recently used items are discarded first when the cache reaches its maximum size. In this example, we set `maxsize` to `None`, which means the cache will store results for all input values. However, in a real-world scenario, you may want to set a reasonable `maxsize` to avoid memory issues.",
  "timestamp": "2026-02-12T02:28:19.248059",
  "model": "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
}