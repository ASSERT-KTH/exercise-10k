{
  "prompt": "Create a program that takes an image description as input and generates a caption.",
  "answer": "**Image Caption Generator Program**\n=====================================\n\nThis program uses Natural Language Processing (NLP) techniques to generate a caption based on an image description.\n\n**Requirements**\n---------------\n\n* Python 3.8+\n* NLTK library (`pip install nltk`)\n* Transformers library (`pip install transformers`)\n\n**Code**\n------\n```python\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# Load pre-trained model and tokenizer\nmodel_name = \"distilbert-base-uncased\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef generate_caption(image_description):\n    \"\"\"\n    Generate a caption based on the image description.\n\n    Args:\n        image_description (str): The description of the image.\n\n    Returns:\n        str: The generated caption.\n    \"\"\"\n    # Tokenize the image description\n    tokens = word_tokenize(image_description)\n\n    # Convert tokens to input IDs and attention mask\n    inputs = tokenizer(tokens, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n\n    # Generate caption using the pre-trained model\n    outputs = model.generate(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n\n    # Convert output IDs to caption text\n    caption = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    return caption\n\n# Example usage\nimage_description = \"A beautiful sunset over a serene lake with a few trees in the foreground.\"\ncaption = generate_caption(image_description)\nprint(\"Generated Caption:\", caption)\n```\n**How it Works**\n----------------\n\n1. The program loads a pre-trained DistilBERT model and tokenizer using the Transformers library.\n2. The `generate_caption` function takes an image description as input and tokenizes it using NLTK.\n3. The tokens are then converted to input IDs and attention mask using the tokenizer.\n4. The pre-trained model generates a caption based on the input IDs and attention mask.\n5. The output IDs are converted to caption text using the tokenizer.\n6. The generated caption is returned as output.\n\n**Note**\n-----\n\n* This program uses a pre-trained model, which may not always produce accurate or relevant captions.\n* The quality of the generated caption depends on the quality of the input image description and the pre-trained model.\n* You can fine-tune the pre-trained model on your own dataset to improve the accuracy of the generated captions.",
  "timestamp": "2026-02-10T23:48:13.554922",
  "model": "RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic"
}