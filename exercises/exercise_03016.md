## Exercise
Write a program to split a given string into tokens based on whitespace characters.

## Reference Solution
```python
def tokenize_string(input_string):
    """
    Split a string into tokens based on whitespace characters.

    Args:
        input_string (str): The input string to be tokenized.

    Returns:
        list: A list of tokens.
    """
    return input_string.split()

def main():
    # Example usage
    input_string = "Hello World, this is a test string."
    tokens = tokenize_string(input_string)
    print("Tokens:")
    for i, token in enumerate(tokens):
        print(f"Token {i+1}: {token}")

if __name__ == "__main__":
    main()
```

## Generated Output
```
Tokens:
Token 1: Hello
Token 2: World,
Token 3: this
Token 4: is
Token 5: a
Token 6: test
Token 7: string.
```

generated by python 3.10.13

solution generated by RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
