## Exercise
Given a string, split it into individual tokens (words or punctuation) and return them in a list.

## Reference Solution
```python
import re

def tokenize_string(input_string):
    """
    Tokenize a string into individual words or punctuation.

    Args:
        input_string (str): The input string to be tokenized.

    Returns:
        list: A list of tokens (words or punctuation) from the input string.
    """
    # Use regular expression to split the string into tokens
    tokens = re.findall(r'\w+|[^\w\s]', input_string)
    
    return tokens

# Example usage:
input_string = "Hello, world! This is a test."
print(tokenize_string(input_string))
```

```python
['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '.']
```

## Generated Output
```
['Hello', ',', 'world', '!', 'This', 'is', 'a', 'test', '.']
```

generated by python 3.10.13

solution generated by RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
