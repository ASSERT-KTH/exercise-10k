## Exercise
Create a function that takes the coordinates of two points as arguments and returns the distance between them

## Reference Solution
```python
import math

def calculate_distance(point1, point2):
    """
    Calculate the distance between two points in a 2D or 3D space.

    Args:
        point1 (list or tuple): The coordinates of the first point.
        point2 (list or tuple): The coordinates of the second point.

    Returns:
        float: The distance between the two points.
    """
    # Check if both points have the same number of dimensions
    if len(point1) != len(point2):
        raise ValueError("Both points must have the same number of dimensions")

    # Calculate the squared differences between corresponding coordinates
    squared_differences = [(a - b) ** 2 for a, b in zip(point1, point2)]

    # Calculate the Euclidean distance using the Pythagorean theorem
    distance = math.sqrt(sum(squared_differences))

    return distance

# Example usage:
point1 = (1, 2, 3)
point2 = (4, 5, 6)
print(calculate_distance(point1, point2))
```

## Generated Output
```
5.196152422706632
```

generated by python 3.10.13

solution generated by RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
