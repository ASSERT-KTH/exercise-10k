## Exercise
Create a program that converts a given fraction to a decimal number.

## Reference Solution
```python
from fractions import Fraction

def fraction_to_decimal(numerator, denominator):
    """
    Converts a fraction to a decimal number.

    Args:
        numerator (int): The numerator of the fraction.
        denominator (int): The denominator of the fraction.

    Returns:
        float: The decimal representation of the fraction.
    """
    # Check for division by zero
    if denominator == 0:
        raise ZeroDivisionError("Cannot divide by zero")

    # Use the Fraction class to create a fraction object
    fraction = Fraction(numerator, denominator)

    # Convert the fraction to a float
    decimal = float(fraction)

    return decimal

def main():
    # Get user input
    numerator = int(input("Enter the numerator: "))
    denominator = int(input("Enter the denominator: "))

    # Convert the fraction to a decimal
    decimal = fraction_to_decimal(numerator, denominator)

    # Print the result
    print(f"The decimal representation of {numerator}/{denominator} is {decimal}")

if __name__ == "__main__":
    main()
```

## Generated Output
```
Enter the numerator: 
Traceback (most recent call last):
  File "/tmp/tmp27q16v66.py", line 38, in <module>
    main()
  File "/tmp/tmp27q16v66.py", line 28, in main
    numerator = int(input("Enter the numerator: "))
ValueError: invalid literal for int() with base 10: '1/2'
```

generated by python 3.10.13

solution generated by RedHatAI/Llama-3.3-70B-Instruct-FP8-dynamic
